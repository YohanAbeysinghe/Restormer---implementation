{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gyexYBYiXw8s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision.transforms.functional as T\n",
        "from torchvision.transforms import RandomCrop\n",
        "\n",
        "from rain_dataset import RainDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lp2V-NPxYRaU"
      },
      "outputs": [],
      "source": [
        "class MDTA(nn.Module):\n",
        "    def __init__(self, channels, num_heads):\n",
        "        super(MDTA, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.temperature = nn.Parameter(torch.ones(1, num_heads, 1, 1))\n",
        "\n",
        "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1, bias=False)\n",
        "        self.qkv_conv = nn.Conv2d(channels * 3, channels * 3, kernel_size=3, padding=1, groups=channels * 3, bias=False)\n",
        "        self.project_out = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        q, k, v = self.qkv_conv(self.qkv(x)).chunk(3, dim=1)\n",
        "\n",
        "        q = q.reshape(b, self.num_heads, -1, h * w)\n",
        "        k = k.reshape(b, self.num_heads, -1, h * w)\n",
        "        v = v.reshape(b, self.num_heads, -1, h * w)\n",
        "        q, k = F.normalize(q, dim=-1), F.normalize(k, dim=-1)\n",
        "\n",
        "        attn = torch.softmax(torch.matmul(q, k.transpose(-2, -1).contiguous()) * self.temperature, dim=-1)\n",
        "        out = self.project_out(torch.matmul(attn, v).reshape(b, -1, h, w))\n",
        "        return out\n",
        "\n",
        "\n",
        "class GDFN(nn.Module):\n",
        "    def __init__(self, channels, expansion_factor):\n",
        "        super(GDFN, self).__init__()\n",
        "\n",
        "        hidden_channels = int(channels * expansion_factor)\n",
        "        self.project_in = nn.Conv2d(channels, hidden_channels * 2, kernel_size=1, bias=False)\n",
        "        self.conv = nn.Conv2d(hidden_channels * 2, hidden_channels * 2, kernel_size=3, padding=1,\n",
        "                              groups=hidden_channels * 2, bias=False)\n",
        "        self.project_out = nn.Conv2d(hidden_channels, channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1, x2 = self.conv(self.project_in(x)).chunk(2, dim=1)\n",
        "        x = self.project_out(F.gelu(x1) * x2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, channels, num_heads, expansion_factor):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(channels)\n",
        "        self.attn = MDTA(channels, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(channels)\n",
        "        self.ffn = GDFN(channels, expansion_factor)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        x = x + self.attn(self.norm1(x.reshape(b, c, -1).transpose(-2, -1).contiguous()).transpose(-2, -1)\n",
        "                          .contiguous().reshape(b, c, h, w))\n",
        "        x = x + self.ffn(self.norm2(x.reshape(b, c, -1).transpose(-2, -1).contiguous()).transpose(-2, -1)\n",
        "                         .contiguous().reshape(b, c, h, w))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(DownSample, self).__init__()\n",
        "        self.body = nn.Sequential(nn.Conv2d(channels, channels // 2, kernel_size=3, padding=1, bias=False),\n",
        "                                  nn.PixelUnshuffle(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.body(x)\n",
        "\n",
        "\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(UpSample, self).__init__()\n",
        "        self.body = nn.Sequential(nn.Conv2d(channels, channels * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                  nn.PixelShuffle(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.body(x)\n",
        "\n",
        "\n",
        "\n",
        "class Restormer(nn.Module):\n",
        "    def __init__(self, num_blocks=[4, 6, 6, 8], num_heads=[1, 2, 4, 8], channels=[48, 96, 192, 384], num_refinement=4,\n",
        "                 expansion_factor=2.66):\n",
        "        super(Restormer, self).__init__()\n",
        "\n",
        "        self.embed_conv = nn.Conv2d(3, channels[0], kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.encoders = nn.ModuleList([nn.Sequential(*[TransformerBlock(\n",
        "            num_ch, num_ah, expansion_factor) for _ in range(num_tb)]) for num_tb, num_ah, num_ch in\n",
        "                                       zip(num_blocks, num_heads, channels)])\n",
        "        # the number of down sample or up sample == the number of encoder - 1\n",
        "        self.downs = nn.ModuleList([DownSample(num_ch) for num_ch in channels[:-1]])\n",
        "        self.ups = nn.ModuleList([UpSample(num_ch) for num_ch in list(reversed(channels))[:-1]])\n",
        "        # the number of reduce block == the number of decoder - 1\n",
        "        self.reduces = nn.ModuleList([nn.Conv2d(channels[i], channels[i - 1], kernel_size=1, bias=False)\n",
        "                                      for i in reversed(range(2, len(channels)))])\n",
        "        # the number of decoder == the number of encoder - 1\n",
        "        self.decoders = nn.ModuleList([nn.Sequential(*[TransformerBlock(channels[2], num_heads[2], expansion_factor)\n",
        "                                                       for _ in range(num_blocks[2])])])\n",
        "        self.decoders.append(nn.Sequential(*[TransformerBlock(channels[1], num_heads[1], expansion_factor)\n",
        "                                             for _ in range(num_blocks[1])]))\n",
        "        # the channel of last one is not change\n",
        "        self.decoders.append(nn.Sequential(*[TransformerBlock(channels[1], num_heads[0], expansion_factor)\n",
        "                                             for _ in range(num_blocks[0])]))\n",
        "\n",
        "        self.refinement = nn.Sequential(*[TransformerBlock(channels[1], num_heads[0], expansion_factor)\n",
        "                                          for _ in range(num_refinement)])\n",
        "        self.output = nn.Conv2d(channels[1], 3, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fo = self.embed_conv(x)\n",
        "        out_enc1 = self.encoders[0](fo)\n",
        "        out_enc2 = self.encoders[1](self.downs[0](out_enc1))\n",
        "        out_enc3 = self.encoders[2](self.downs[1](out_enc2))\n",
        "        out_enc4 = self.encoders[3](self.downs[2](out_enc3))\n",
        "\n",
        "        out_dec3 = self.decoders[0](self.reduces[0](torch.cat([self.ups[0](out_enc4), out_enc3], dim=1)))\n",
        "        out_dec2 = self.decoders[1](self.reduces[1](torch.cat([self.ups[1](out_dec3), out_enc2], dim=1)))\n",
        "        fd = self.decoders[2](torch.cat([self.ups[2](out_dec2), out_enc1], dim=1))\n",
        "        fr = self.refinement(fd)\n",
        "        out = self.output(fr) + x\n",
        "        return out\n",
        "\n",
        "\n",
        "def initialize_args():\n",
        "    class Args:\n",
        "        def __init__(self):\n",
        "            self.data_path = 'data'\n",
        "            self.data_name = 'rain100L'\n",
        "            self.save_path = 'result'\n",
        "            self.num_blocks = [2, 3, 3, 4] #[4, 6, 6, 8]\n",
        "            self.num_heads = [1, 2, 4, 8]\n",
        "            self.channels = [48, 96, 192, 384]\n",
        "            self.expansion_factor = 2.66\n",
        "            self.num_refinement = 4\n",
        "            self.num_iter = 300000\n",
        "            self.batch_size = [32, 20, 16, 8, 4, 4]   #[64, 40, 32, 16, 8, 8] #[40, 32, 16, 8, 8]\n",
        "            self.patch_size = [32, 40, 48, 64, 80, 96] #[64, 80, 96, 128, 160, 192] #[128, 160, 192, 256, 320, 384] #[160, 192, 256, 320, 384]\n",
        "            self.lr = 0.0003\n",
        "            self.milestone = [92000, 156000, 204000, 240000, 276000] #[92000, 156000, 204000, 240000, 276000]\n",
        "            self.workers = 8\n",
        "            self.seed = -1\n",
        "            self.model_file = None\n",
        "\n",
        "    return Args()\n",
        "\n",
        "\n",
        "\n",
        "def rgb_to_y(x):\n",
        "    rgb_to_grey = torch.tensor([0.256789, 0.504129, 0.097906], dtype=x.dtype, device=x.device).view(1, -1, 1, 1)\n",
        "    return torch.sum(x * rgb_to_grey, dim=1, keepdim=True).add(16.0)\n",
        "\n",
        "\n",
        "def psnr(x, y, data_range=255.0):\n",
        "    x, y = x / data_range, y / data_range\n",
        "    mse = torch.mean((x - y) ** 2)\n",
        "    score = - 10 * torch.log10(mse)\n",
        "    return score\n",
        "\n",
        "\n",
        "def ssim(x, y, kernel_size=11, kernel_sigma=1.5, data_range=255.0, k1=0.01, k2=0.03):\n",
        "    x, y = x / data_range, y / data_range\n",
        "    # average pool image if the size is large enough\n",
        "    f = max(1, round(min(x.size()[-2:]) / 256))\n",
        "    if f > 1:\n",
        "        x, y = F.avg_pool2d(x, kernel_size=f), F.avg_pool2d(y, kernel_size=f)\n",
        "\n",
        "    # gaussian filter\n",
        "    coords = torch.arange(kernel_size, dtype=x.dtype, device=x.device)\n",
        "    coords -= (kernel_size - 1) / 2.0\n",
        "    g = coords ** 2\n",
        "    g = (- (g.unsqueeze(0) + g.unsqueeze(1)) / (2 * kernel_sigma ** 2)).exp()\n",
        "    g /= g.sum()\n",
        "    kernel = g.unsqueeze(0).repeat(x.size(1), 1, 1, 1)\n",
        "\n",
        "    # compute\n",
        "    c1, c2 = k1 ** 2, k2 ** 2\n",
        "    n_channels = x.size(1)\n",
        "    mu_x = F.conv2d(x, weight=kernel, stride=1, padding=0, groups=n_channels)\n",
        "    mu_y = F.conv2d(y, weight=kernel, stride=1, padding=0, groups=n_channels)\n",
        "\n",
        "    mu_xx, mu_yy, mu_xy = mu_x ** 2, mu_y ** 2, mu_x * mu_y\n",
        "    sigma_xx = F.conv2d(x ** 2, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_xx\n",
        "    sigma_yy = F.conv2d(y ** 2, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_yy\n",
        "    sigma_xy = F.conv2d(x * y, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_xy\n",
        "\n",
        "    # contrast sensitivity (CS) with alpha = beta = gamma = 1.\n",
        "    cs = (2.0 * sigma_xy + c2) / (sigma_xx + sigma_yy + c2)\n",
        "    # structural similarity (SSIM)\n",
        "    ss = (2.0 * mu_xy + c1) / (mu_xx + mu_yy + c1) * cs\n",
        "    return ss.mean()\n",
        "\n",
        "\n",
        "\n",
        "def test_loop(net, data_loader, num_iter):\n",
        "    net.eval()\n",
        "    total_psnr, total_ssim, count = 0.0, 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(data_loader, initial=1, dynamic_ncols=True)\n",
        "        for rain, norain, name, h, w in test_bar:\n",
        "            rain, norain = rain.cuda(), norain.cuda()\n",
        "            out = torch.clamp((torch.clamp(model(rain)[:, :, :h, :w], 0, 1).mul(255)), 0, 255).byte()\n",
        "            norain = torch.clamp(norain[:, :, :h, :w].mul(255), 0, 255).byte()\n",
        "            # computer the metrics with Y channel and double precision\n",
        "            y, gt = rgb_to_y(out.double()), rgb_to_y(norain.double())\n",
        "            current_psnr, current_ssim = psnr(y, gt), ssim(y, gt)\n",
        "            total_psnr += current_psnr.item()\n",
        "            total_ssim += current_ssim.item()\n",
        "            count += 1\n",
        "            save_path = '{}/{}/{}'.format(args.save_path, args.data_name, name[0])\n",
        "            if not os.path.exists(os.path.dirname(save_path)):\n",
        "                os.makedirs(os.path.dirname(save_path))\n",
        "            Image.fromarray(out.squeeze(dim=0).permute(1, 2, 0).contiguous().cpu().numpy()).save(save_path)\n",
        "            test_bar.set_description('Test Iter: [{}/{}] PSNR: {:.2f} SSIM: {:.3f}'\n",
        "                                     .format(num_iter, 1 if args.model_file else args.num_iter,\n",
        "                                             total_psnr / count, total_ssim / count))\n",
        "    return total_psnr / count, total_ssim / count\n",
        "\n",
        "\n",
        "def save_loop(net, data_loader, num_iter):\n",
        "    global best_psnr, best_ssim\n",
        "    val_psnr, val_ssim = test_loop(net, data_loader, num_iter)\n",
        "    results['PSNR'].append('{:.2f}'.format(val_psnr))\n",
        "    results['SSIM'].append('{:.3f}'.format(val_ssim))\n",
        "    # save statistics\n",
        "    data_frame = pd.DataFrame(data=results, index=range(1, (num_iter if args.model_file else num_iter // 1000) + 1))\n",
        "    data_frame.to_csv('{}/{}.csv'.format(args.save_path, args.data_name), index_label='Iter', float_format='%.3f')\n",
        "    if val_psnr > best_psnr and val_ssim > best_ssim:\n",
        "        best_psnr, best_ssim = val_psnr, val_ssim\n",
        "        with open('{}/{}.txt'.format(args.save_path, args.data_name), 'w') as f:\n",
        "            f.write('Iter: {} PSNR:{:.2f} SSIM:{:.3f}'.format(num_iter, best_psnr, best_ssim))\n",
        "        torch.save(model.state_dict(), '{}/{}.pth'.format(args.save_path, args.data_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "PkKTiPiVYXPs",
        "outputId": "8eb5559a-176c-408b-ca1a-c4cd074ad482"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mworkers)\n\u001b[1;32m      7\u001b[0m results, best_psnr, best_ssim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSNR\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSIM\u001b[39m\u001b[38;5;124m'\u001b[39m: []}, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRestormer\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_refinement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpansion_factor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel_file:\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(args\u001b[38;5;241m.\u001b[39mmodel_file))\n",
            "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:892\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    876\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:784\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 784\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    788\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    789\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:807\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 807\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:892\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    876\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    #args = parse_args()\n",
        "    args = initialize_args()\n",
        "    test_dataset = RainDataset(args.data_path, args.data_name, 'test')\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=args.workers)\n",
        "\n",
        "    results, best_psnr, best_ssim = {'PSNR': [], 'SSIM': []}, 0.0, 0.0\n",
        "    model = Restormer(args.num_blocks, args.num_heads, args.channels, args.num_refinement, args.expansion_factor).cuda()\n",
        "    if args.model_file:\n",
        "        model.load_state_dict(torch.load(args.model_file))\n",
        "        save_loop(model, test_loader, 1)\n",
        "    else:\n",
        "        optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
        "        lr_scheduler = CosineAnnealingLR(optimizer, T_max=args.num_iter, eta_min=1e-6)\n",
        "        total_loss, total_num, results['Loss'], i = 0.0, 0, [], 0\n",
        "        train_bar = tqdm(range(1, args.num_iter + 1), initial=1, dynamic_ncols=True)\n",
        "        for n_iter in train_bar:\n",
        "            # progressive learning\n",
        "            if n_iter == 1 or n_iter - 1 in args.milestone:\n",
        "                end_iter = args.milestone[i] if i < len(args.milestone) else args.num_iter\n",
        "                start_iter = args.milestone[i - 1] if i > 0 else 0\n",
        "                length = args.batch_size[i] * (end_iter - start_iter)\n",
        "                train_dataset = RainDataset(args.data_path, args.data_name, 'train', args.patch_size[i], length)\n",
        "                train_loader = iter(DataLoader(train_dataset, args.batch_size[i], True, num_workers=args.workers))\n",
        "                i += 1\n",
        "            # train\n",
        "            model.train()\n",
        "            rain, norain, name, h, w = next(train_loader)\n",
        "            rain, norain = rain.cuda(), norain.cuda()\n",
        "\n",
        "            out = model(rain)\n",
        "            loss = F.l1_loss(out, norain)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_num += rain.size(0)\n",
        "            total_loss += loss.item() * rain.size(0)\n",
        "            train_bar.set_description('Train Iter: [{}/{}] Loss: {:.3f}'\n",
        "                                      .format(n_iter, args.num_iter, total_loss / total_num))\n",
        "\n",
        "            lr_scheduler.step()\n",
        "            if n_iter % 1000 == 0:\n",
        "                results['Loss'].append('{:.3f}'.format(total_loss / total_num))\n",
        "                save_loop(model, test_loader, n_iter)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9 (pytorch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
