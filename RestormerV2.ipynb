{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as T\n",
    "from torch.backends import cudnn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import RandomCrop\n",
    "from rain_dataset import RainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDTA(nn.Module):\n",
    "    def __init__(self, channels, num_heads):\n",
    "        super(MDTA, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.temperature = nn.Parameter(torch.ones(1, num_heads, 1, 1))\n",
    "\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1, bias=False)\n",
    "        self.qkv_conv = nn.Conv2d(channels * 3, channels * 3, kernel_size=3, padding=1, groups=channels * 3, bias=False)\n",
    "        self.project_out = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        q, k, v = self.qkv_conv(self.qkv(x)).chunk(3, dim=1)\n",
    "\n",
    "        q = q.reshape(b, self.num_heads, -1, h * w)\n",
    "        k = k.reshape(b, self.num_heads, -1, h * w)\n",
    "        v = v.reshape(b, self.num_heads, -1, h * w)\n",
    "        q, k = F.normalize(q, dim=-1), F.normalize(k, dim=-1)\n",
    "\n",
    "        attn = torch.softmax(torch.matmul(q, k.transpose(-2, -1).contiguous()) * self.temperature, dim=-1)\n",
    "        out = self.project_out(torch.matmul(attn, v).reshape(b, -1, h, w))\n",
    "        return out\n",
    "\n",
    "\n",
    "class GDFN(nn.Module):\n",
    "    def __init__(self, channels, expansion_factor):\n",
    "        super(GDFN, self).__init__()\n",
    "\n",
    "        hidden_channels = int(channels * expansion_factor)\n",
    "        self.project_in = nn.Conv2d(channels, hidden_channels * 2, kernel_size=1, bias=False)\n",
    "        self.conv = nn.Conv2d(hidden_channels * 2, hidden_channels * 2, kernel_size=3, padding=1,\n",
    "                              groups=hidden_channels * 2, bias=False)\n",
    "        self.project_out = nn.Conv2d(hidden_channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = self.conv(self.project_in(x)).chunk(2, dim=1)\n",
    "        x = self.project_out(F.gelu(x1) * x2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, channels, num_heads, expansion_factor):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(channels)\n",
    "        self.attn = MDTA(channels, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(channels)\n",
    "        self.ffn = GDFN(channels, expansion_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x = x + self.attn(self.norm1(x.reshape(b, c, -1).transpose(-2, -1).contiguous()).transpose(-2, -1)\n",
    "                          .contiguous().reshape(b, c, h, w))\n",
    "        x = x + self.ffn(self.norm2(x.reshape(b, c, -1).transpose(-2, -1).contiguous()).transpose(-2, -1)\n",
    "                         .contiguous().reshape(b, c, h, w))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.body = nn.Sequential(nn.Conv2d(channels, channels // 2, kernel_size=3, padding=1, bias=False),\n",
    "                                  nn.PixelUnshuffle(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.body(x)\n",
    "\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.body = nn.Sequential(nn.Conv2d(channels, channels * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                  nn.PixelShuffle(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.body(x)\n",
    "\n",
    "\n",
    "\n",
    "class Restormer(nn.Module):\n",
    "    def __init__(self, num_blocks=[4, 6, 6, 8], num_heads=[1, 2, 4, 8], channels=[48, 96, 192, 384], num_refinement=4,\n",
    "                 expansion_factor=2.66):\n",
    "        super(Restormer, self).__init__()\n",
    "\n",
    "        self.embed_conv = nn.Conv2d(3, channels[0], kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.encoders = nn.ModuleList([nn.Sequential(*[TransformerBlock(\n",
    "            num_ch, num_ah, expansion_factor) for _ in range(num_tb)]) for num_tb, num_ah, num_ch in\n",
    "                                       zip(num_blocks, num_heads, channels)])\n",
    "        # the number of down sample or up sample == the number of encoder - 1\n",
    "        self.downs = nn.ModuleList([DownSample(num_ch) for num_ch in channels[:-1]])\n",
    "        self.ups = nn.ModuleList([UpSample(num_ch) for num_ch in list(reversed(channels))[:-1]])\n",
    "        # the number of reduce block == the number of decoder - 1\n",
    "        self.reduces = nn.ModuleList([nn.Conv2d(channels[i], channels[i - 1], kernel_size=1, bias=False)\n",
    "                                      for i in reversed(range(2, len(channels)))])\n",
    "        # the number of decoder == the number of encoder - 1\n",
    "        self.decoders = nn.ModuleList([nn.Sequential(*[TransformerBlock(channels[2], num_heads[2], expansion_factor)\n",
    "                                                       for _ in range(num_blocks[2])])])\n",
    "        self.decoders.append(nn.Sequential(*[TransformerBlock(channels[1], num_heads[1], expansion_factor)\n",
    "                                             for _ in range(num_blocks[1])]))\n",
    "        # the channel of last one is not change\n",
    "        self.decoders.append(nn.Sequential(*[TransformerBlock(channels[1], num_heads[0], expansion_factor)\n",
    "                                             for _ in range(num_blocks[0])]))\n",
    "\n",
    "        self.refinement = nn.Sequential(*[TransformerBlock(channels[1], num_heads[0], expansion_factor)\n",
    "                                          for _ in range(num_refinement)])\n",
    "        self.output = nn.Conv2d(channels[1], 3, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fo = self.embed_conv(x)\n",
    "        out_enc1 = self.encoders[0](fo)\n",
    "        out_enc2 = self.encoders[1](self.downs[0](out_enc1))\n",
    "        out_enc3 = self.encoders[2](self.downs[1](out_enc2))\n",
    "        out_enc4 = self.encoders[3](self.downs[2](out_enc3))\n",
    "\n",
    "        out_dec3 = self.decoders[0](self.reduces[0](torch.cat([self.ups[0](out_enc4), out_enc3], dim=1)))\n",
    "        out_dec2 = self.decoders[1](self.reduces[1](torch.cat([self.ups[1](out_dec3), out_enc2], dim=1)))\n",
    "        fd = self.decoders[2](torch.cat([self.ups[2](out_dec2), out_enc1], dim=1))\n",
    "        fr = self.refinement(fd)\n",
    "        out = self.output(fr) + x\n",
    "        return out\n",
    "\n",
    "\n",
    "def initialize_args():\n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            self.data_path = '/home/data'\n",
    "            self.data_name = 'rain100L'\n",
    "            self.save_path = 'result'\n",
    "            self.num_blocks = [4, 6, 6, 8]\n",
    "            self.num_heads = [1, 2, 4, 8]\n",
    "            self.channels = [48, 96, 192, 384]\n",
    "            self.expansion_factor = 2.66\n",
    "            self.num_refinement = 4\n",
    "            self.num_iter = 300000\n",
    "            self.batch_size = [64, 40, 32, 16, 8, 8]\n",
    "            self.patch_size = [128, 160, 192, 256, 320, 384]\n",
    "            self.lr = 0.0003\n",
    "            self.milestone = [92000, 156000, 204000, 240000, 276000]\n",
    "            self.workers = 8\n",
    "            self.seed = -1\n",
    "            self.model_file = None\n",
    "\n",
    "    return Args()\n",
    "\n",
    "\n",
    "\n",
    "def rgb_to_y(x):\n",
    "    rgb_to_grey = torch.tensor([0.256789, 0.504129, 0.097906], dtype=x.dtype, device=x.device).view(1, -1, 1, 1)\n",
    "    return torch.sum(x * rgb_to_grey, dim=1, keepdim=True).add(16.0)\n",
    "\n",
    "\n",
    "def psnr(x, y, data_range=255.0):\n",
    "    x, y = x / data_range, y / data_range\n",
    "    mse = torch.mean((x - y) ** 2)\n",
    "    score = - 10 * torch.log10(mse)\n",
    "    return score\n",
    "\n",
    "\n",
    "def ssim(x, y, kernel_size=11, kernel_sigma=1.5, data_range=255.0, k1=0.01, k2=0.03):\n",
    "    x, y = x / data_range, y / data_range\n",
    "    # average pool image if the size is large enough\n",
    "    f = max(1, round(min(x.size()[-2:]) / 256))\n",
    "    if f > 1:\n",
    "        x, y = F.avg_pool2d(x, kernel_size=f), F.avg_pool2d(y, kernel_size=f)\n",
    "\n",
    "    # gaussian filter\n",
    "    coords = torch.arange(kernel_size, dtype=x.dtype, device=x.device)\n",
    "    coords -= (kernel_size - 1) / 2.0\n",
    "    g = coords ** 2\n",
    "    g = (- (g.unsqueeze(0) + g.unsqueeze(1)) / (2 * kernel_sigma ** 2)).exp()\n",
    "    g /= g.sum()\n",
    "    kernel = g.unsqueeze(0).repeat(x.size(1), 1, 1, 1)\n",
    "\n",
    "    # compute\n",
    "    c1, c2 = k1 ** 2, k2 ** 2\n",
    "    n_channels = x.size(1)\n",
    "    mu_x = F.conv2d(x, weight=kernel, stride=1, padding=0, groups=n_channels)\n",
    "    mu_y = F.conv2d(y, weight=kernel, stride=1, padding=0, groups=n_channels)\n",
    "\n",
    "    mu_xx, mu_yy, mu_xy = mu_x ** 2, mu_y ** 2, mu_x * mu_y\n",
    "    sigma_xx = F.conv2d(x ** 2, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_xx\n",
    "    sigma_yy = F.conv2d(y ** 2, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_yy\n",
    "    sigma_xy = F.conv2d(x * y, weight=kernel, stride=1, padding=0, groups=n_channels) - mu_xy\n",
    "\n",
    "    # contrast sensitivity (CS) with alpha = beta = gamma = 1.\n",
    "    cs = (2.0 * sigma_xy + c2) / (sigma_xx + sigma_yy + c2)\n",
    "    # structural similarity (SSIM)\n",
    "    ss = (2.0 * mu_xy + c1) / (mu_xx + mu_yy + c1) * cs\n",
    "    return ss.mean()\n",
    "\n",
    "\n",
    "\n",
    "def test_loop(net, data_loader, num_iter):\n",
    "    net.eval()\n",
    "    total_psnr, total_ssim, count = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(data_loader, initial=1, dynamic_ncols=True)\n",
    "        for rain, norain, name, h, w in test_bar:\n",
    "            rain, norain = rain.cuda(), norain.cuda()\n",
    "            out = torch.clamp((torch.clamp(model(rain)[:, :, :h, :w], 0, 1).mul(255)), 0, 255).byte()\n",
    "            norain = torch.clamp(norain[:, :, :h, :w].mul(255), 0, 255).byte()\n",
    "            # computer the metrics with Y channel and double precision\n",
    "            y, gt = rgb_to_y(out.double()), rgb_to_y(norain.double())\n",
    "            current_psnr, current_ssim = psnr(y, gt), ssim(y, gt)\n",
    "            total_psnr += current_psnr.item()\n",
    "            total_ssim += current_ssim.item()\n",
    "            count += 1\n",
    "            save_path = '{}/{}/{}'.format(args.save_path, args.data_name, name[0])\n",
    "            if not os.path.exists(os.path.dirname(save_path)):\n",
    "                os.makedirs(os.path.dirname(save_path))\n",
    "            Image.fromarray(out.squeeze(dim=0).permute(1, 2, 0).contiguous().cpu().numpy()).save(save_path)\n",
    "            test_bar.set_description('Test Iter: [{}/{}] PSNR: {:.2f} SSIM: {:.3f}'\n",
    "                                     .format(num_iter, 1 if args.model_file else args.num_iter,\n",
    "                                             total_psnr / count, total_ssim / count))\n",
    "    return total_psnr / count, total_ssim / count\n",
    "\n",
    "\n",
    "def save_loop(net, data_loader, num_iter):\n",
    "    global best_psnr, best_ssim\n",
    "    val_psnr, val_ssim = test_loop(net, data_loader, num_iter)\n",
    "    results['PSNR'].append('{:.2f}'.format(val_psnr))\n",
    "    results['SSIM'].append('{:.3f}'.format(val_ssim))\n",
    "    # save statistics\n",
    "    data_frame = pd.DataFrame(data=results, index=range(1, (num_iter if args.model_file else num_iter // 1000) + 1))\n",
    "    data_frame.to_csv('{}/{}.csv'.format(args.save_path, args.data_name), index_label='Iter', float_format='%.3f')\n",
    "    if val_psnr > best_psnr and val_ssim > best_ssim:\n",
    "        best_psnr, best_ssim = val_psnr, val_ssim\n",
    "        with open('{}/{}.txt'.format(args.save_path, args.data_name), 'w') as f:\n",
    "            f.write('Iter: {} PSNR:{:.2f} SSIM:{:.3f}'.format(num_iter, best_psnr, best_ssim))\n",
    "        torch.save(model.state_dict(), '{}/{}.pth'.format(args.save_path, args.data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300000 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "Caught ZeroDivisionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/yohanabeysinghe/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/yohanabeysinghe/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/yohanabeysinghe/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/yohanabeysinghe/Mac/Codes/ML/Projects/Restormer-implementation/rain_dataset.py\", line 33, in __getitem__\n    image_name = os.path.basename(self.rain_images[idx % self.num])\nZeroDivisionError: integer division or modulo by zero\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 28\u001b[0m rain, norain, name, h, w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m rain, norain \u001b[38;5;241m=\u001b[39m rain(), norain()\n\u001b[1;32m     30\u001b[0m out \u001b[38;5;241m=\u001b[39m model(rain)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:635\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1347\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1373\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1373\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/_utils.py:636\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 636\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: Caught ZeroDivisionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/yohanabeysinghe/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/yohanabeysinghe/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/yohanabeysinghe/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/yohanabeysinghe/Mac/Codes/ML/Projects/Restormer-implementation/rain_dataset.py\", line 33, in __getitem__\n    image_name = os.path.basename(self.rain_images[idx % self.num])\nZeroDivisionError: integer division or modulo by zero\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #args = parse_args()\n",
    "    args = initialize_args()\n",
    "    test_dataset = RainDataset(args.data_path, args.data_name, 'test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=args.workers)\n",
    "\n",
    "    results, best_psnr, best_ssim = {'PSNR': [], 'SSIM': []}, 0.0, 0.0\n",
    "    model = Restormer(args.num_blocks, args.num_heads, args.channels, args.num_refinement, args.expansion_factor)\n",
    "    if args.model_file:\n",
    "        model.load_state_dict(torch.load(args.model_file))\n",
    "        save_loop(model, test_loader, 1)\n",
    "    else:\n",
    "        optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "        lr_scheduler = CosineAnnealingLR(optimizer, T_max=args.num_iter, eta_min=1e-6)\n",
    "        total_loss, total_num, results['Loss'], i = 0.0, 0, [], 0\n",
    "        train_bar = tqdm(range(1, args.num_iter + 1), initial=1, dynamic_ncols=True)\n",
    "        for n_iter in train_bar:\n",
    "            # progressive learning\n",
    "            if n_iter == 1 or n_iter - 1 in args.milestone:\n",
    "                end_iter = args.milestone[i] if i < len(args.milestone) else args.num_iter\n",
    "                start_iter = args.milestone[i - 1] if i > 0 else 0\n",
    "                length = args.batch_size[i] * (end_iter - start_iter)\n",
    "                train_dataset = RainDataset(args.data_path, args.data_name, 'train', args.patch_size[i], length)\n",
    "                train_loader = iter(DataLoader(train_dataset, args.batch_size[i], True, num_workers=args.workers))\n",
    "                i += 1\n",
    "            # train\n",
    "            model.train()\n",
    "            rain, norain, name, h, w = next(train_loader)\n",
    "            rain, norain = rain(), norain()\n",
    "            out = model(rain)\n",
    "            loss = F.l1_loss(out, norain)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_num += rain.size(0)\n",
    "            total_loss += loss.item() * rain.size(0)\n",
    "            train_bar.set_description('Train Iter: [{}/{}] Loss: {:.3f}'\n",
    "                                      .format(n_iter, args.num_iter, total_loss / total_num))\n",
    "\n",
    "            lr_scheduler.step()\n",
    "            if n_iter % 1000 == 0:\n",
    "                results['Loss'].append('{:.3f}'.format(total_loss / total_num))\n",
    "                save_loop(model, test_loader, n_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
